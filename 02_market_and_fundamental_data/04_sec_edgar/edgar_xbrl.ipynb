{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with filing data from the SEC's EDGAR service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:44:09.848255Z",
     "start_time": "2021-06-07T15:44:09.846445Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:44:10.347273Z",
     "start_time": "2021-06-07T15:44:09.849525Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import json\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile, BadZipFile\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:44:10.349927Z",
     "start_time": "2021-06-07T15:44:10.348221Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:44:10.360919Z",
     "start_time": "2021-06-07T15:44:10.350732Z"
    }
   },
   "outputs": [],
   "source": [
    "# store data in this directory since we won't use it in other chapters\n",
    "data_path = Path('data') # perhaps set to external harddrive to accomodate large amount of data\n",
    "if not data_path.exists():\n",
    "    data_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download FS & Notes Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code downloads and extracts all historical filings contained in the [Financial Statement and Notes](https://www.sec.gov/dera/data/financial-statement-and-notes-data-set.html) (FSN) datasets from Q1/2014 through Q3/2020. \n",
    "\n",
    "> The SEC has moved to a monthly cadence after Q3/2020; feel free to extend the code by creating the correpsonding file names (see linked website) and download those as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloads over 40GB of data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:44:10.375969Z",
     "start_time": "2021-06-07T15:44:10.361753Z"
    }
   },
   "outputs": [],
   "source": [
    "SEC_URL = 'https://www.sec.gov/'\n",
    "FSN_PATH = 'files/dera/data/financial-statement-and-notes-data-sets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:44:10.403299Z",
     "start_time": "2021-06-07T15:44:10.380518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2014, 1),\n",
       " (2014, 2),\n",
       " (2014, 3),\n",
       " (2014, 4),\n",
       " (2015, 1),\n",
       " (2015, 2),\n",
       " (2015, 3),\n",
       " (2015, 4),\n",
       " (2016, 1),\n",
       " (2016, 2),\n",
       " (2016, 3),\n",
       " (2016, 4),\n",
       " (2017, 1),\n",
       " (2017, 2),\n",
       " (2017, 3),\n",
       " (2017, 4),\n",
       " (2018, 1),\n",
       " (2018, 2),\n",
       " (2018, 3),\n",
       " (2018, 4),\n",
       " (2019, 1),\n",
       " (2019, 2),\n",
       " (2019, 3),\n",
       " (2019, 4),\n",
       " (2020, 1),\n",
       " (2020, 2),\n",
       " (2020, 3)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filing_periods = [(d.year, d.quarter) for d in pd.date_range('2014', '2020-09-30', freq='Q')]\n",
    "filing_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:04:14.923208Z",
     "start_time": "2021-06-07T15:44:10.408096Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████▎                                                                                                                 | 1/27 [01:07<29:26, 67.94s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4440/1806383785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mlocal_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nBad zip file: {yr} {qtr}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for yr, qtr in tqdm(filing_periods):\n",
    "    # set (and create) directory\n",
    "    path = data_path / f'{yr}_{qtr}' / 'source'\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)\n",
    "    \n",
    "    # define url and get file\n",
    "    filing = f'{yr}q{qtr}_notes.zip'\n",
    "    url = SEC_URL + FSN_PATH + filing\n",
    "    response = requests.get(url).content\n",
    "    \n",
    "    # decompress and save\n",
    "    try:\n",
    "        with ZipFile(BytesIO(response)) as zip_file:\n",
    "            for file in zip_file.namelist():\n",
    "                local_file = path / file\n",
    "                if local_file.exists():\n",
    "                    continue\n",
    "                with local_file.open('wb') as output:\n",
    "                    for line in zip_file.open(file).readlines():\n",
    "                        output.write(line)\n",
    "    except BadZipFile:\n",
    "        print(f'\\nBad zip file: {yr} {qtr}\\n')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is fairly large and to enable faster access than the original text files permit, it is better to convert the text files to binary, columnar parquet format (see Section 'Efficient data storage with pandas' in chapter 2 for a performance comparison of various data-storage options compatible with pandas DataFrames):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Some fo the `txt.tsv` source files contain a small number of faulty lines; the code below drops those lines but indicates the line numbers where you can find the errors if you would like to investigate further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:33:26.732980Z",
     "start_time": "2021-06-07T16:23:56.425987Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in tqdm(sorted(list(data_path.glob('**/*.tsv')))):\n",
    "    # set (and create) directory\n",
    "    parquet_path = f.parent.parent / 'parquet'\n",
    "    if not parquet_path.exists():\n",
    "        parquet_path.mkdir(parents=True)    \n",
    "\n",
    "    # write content to .parquet\n",
    "    file_name = f.stem  + '.parquet'\n",
    "    if not (parquet_path / file_name).exists():\n",
    "        try:\n",
    "            df = pd.read_csv(f, sep='\\t', encoding='latin1', low_memory=False, error_bad_lines=False)\n",
    "            df.to_parquet(parquet_path / file_name)\n",
    "        except Exception as e:\n",
    "            print(e, ' | ', f)\n",
    "        # optional: uncomment to delete original .tsv\n",
    "#         else:\n",
    "            # f.unlink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:33:43.526377Z",
     "start_time": "2021-06-07T16:33:43.368436Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = data_path / '2018_3' / 'source' / '2018q3_notes-metadata.json'\n",
    "with file.open() as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each quarter, the FSN data is organized into eight file sets that contain information about submissions, numbers, taxonomy tags, presentation, and more. Each dataset consists of rows and fields and is provided as a tab-delimited text file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| File | Dataset      | Description                                                 |\n",
    "|------|--------------|-------------------------------------------------------------|\n",
    "| SUB  | Submission   | Identifies each XBRL submission by company, form, date, etc |\n",
    "| TAG  | Tag          | Defines and explains each taxonomy tag                      |\n",
    "| DIM  | Dimension    | Adds detail to numeric and plain text data                  |\n",
    "| NUM  | Numeric      | One row for each distinct data point in filing              |\n",
    "| TXT  | Plain Text   | Contains all non-numeric XBRL fields                        |\n",
    "| REN  | Rendering    | Information for rendering on SEC website                    |\n",
    "| PRE  | Presentation | Detail on tag and number presentation in primary statements |\n",
    "| CAL  | Calculation  | Shows arithmetic relationships among tags                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latest submission file contains around 6,500 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:33:46.579915Z",
     "start_time": "2021-06-07T16:33:46.491388Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_parquet(data_path / '2018_3' / 'parquet' / 'sub.parquet')\n",
    "sub.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get AAPL submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission dataset contains the unique identifiers required to retrieve the filings: the Central Index Key (CIK) and the Accession Number (adsh). The following shows some of the information about Apple's 2018Q1 10-Q filing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:33:48.918331Z",
     "start_time": "2021-06-07T16:33:48.880843Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = 'APPLE INC'\n",
    "apple = sub[sub.name == name].T.dropna().squeeze()\n",
    "key_cols = ['name', 'adsh', 'cik', 'name', 'sic', 'countryba', 'stprba',\n",
    "            'cityba', 'zipba', 'bas1', 'form', 'period', 'fy', 'fp', 'filed']\n",
    "apple.loc[key_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build AAPL fundamentals dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the central index key, we can identify all historical quarterly filings available for Apple, and combine this information to obtain 26 Forms 10-Q and nine annual Forms 10-K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:33:50.709067Z",
     "start_time": "2021-06-07T16:33:49.479737Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aapl_subs = pd.DataFrame()\n",
    "for sub in data_path.glob('**/sub.parquet'):\n",
    "    sub = pd.read_parquet(sub)\n",
    "    aapl_sub = sub[(sub.cik.astype(int) == apple.cik) & (sub.form.isin(['10-Q', '10-K']))]\n",
    "    aapl_subs = pd.concat([aapl_subs, aapl_sub])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find 15 quarterly 10-Q and 4 annual 10-K reports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:33:50.717720Z",
     "start_time": "2021-06-07T16:33:50.711068Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aapl_subs.form.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get numerical filing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Accession Number for each filing, we can now rely on the taxonomies to select the appropriate XBRL tags (listed in the TAG file) from the NUM and TXT files to obtain the numerical or textual/footnote data points of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's extract all numerical data available from the 19 Apple filings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:43.646784Z",
     "start_time": "2021-06-07T16:33:51.977353Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_nums = pd.DataFrame()\n",
    "for num in data_path.glob('**/num.parquet'):\n",
    "    num = pd.read_parquet(num).drop('dimh', axis=1)\n",
    "    aapl_num = num[num.adsh.isin(aapl_subs.adsh)]\n",
    "    print(len(aapl_num))\n",
    "    aapl_nums = pd.concat([aapl_nums, aapl_num])\n",
    "aapl_nums.ddate = pd.to_datetime(aapl_nums.ddate, format='%Y%m%d')   \n",
    "aapl_nums.to_parquet(data_path / 'aapl_nums.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, the nine years of filing history provide us with over 18,000 numerical values for AAPL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:43.659690Z",
     "start_time": "2021-06-07T16:34:43.647741Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aapl_nums.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create P/E Ratio from EPS and stock price data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select a useful field, such as Earnings per Diluted Share (EPS), that we can combine with market data to calculate the popular Price/Earnings (P/E) valuation ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:43.667771Z",
     "start_time": "2021-06-07T16:34:43.660831Z"
    }
   },
   "outputs": [],
   "source": [
    "stock_split = 7\n",
    "split_date = pd.to_datetime('20140604')\n",
    "split_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do need to take into account, however, that Apple split its stock 7:1 on June 4, 2014, and Adjusted Earnings per Share before the split to make earnings comparable, as illustrated in the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:43.732249Z",
     "start_time": "2021-06-07T16:34:43.669116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter by tag; keep only values measuring 1 quarter\n",
    "eps = aapl_nums[(aapl_nums.tag == 'EarningsPerShareDiluted')\n",
    "                & (aapl_nums.qtrs == 1)].drop('tag', axis=1)\n",
    "\n",
    "# Keep only most recent data point from each filing\n",
    "eps = eps.groupby('adsh').apply(lambda x: x.nlargest(n=1, columns=['ddate']))\n",
    "\n",
    "# Adjust earnings prior to stock split downward\n",
    "eps.loc[eps.ddate < split_date,'value'] = eps.loc[eps.ddate < split_date, 'value'].div(7)\n",
    "eps = eps[['ddate', 'value']].set_index('ddate').squeeze().sort_index()\n",
    "eps = eps.rolling(4,min_periods=4).sum().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:44.021729Z",
     "start_time": "2021-06-07T16:34:43.733184Z"
    }
   },
   "outputs": [],
   "source": [
    "eps.plot(lw=2, figsize=(14, 6), title='Diluted Earnings per Share')\n",
    "plt.xlabel('')\n",
    "plt.savefig('diluted eps', dps=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:44.926121Z",
     "start_time": "2021-06-07T16:34:44.022589Z"
    }
   },
   "outputs": [],
   "source": [
    "symbol = 'AAPL.US'\n",
    "\n",
    "aapl_stock = (web.\n",
    "              DataReader(symbol, 'quandl', start=eps.index.min())\n",
    "              .resample('D')\n",
    "              .last()\n",
    "             .loc['2014':eps.index.max()])\n",
    "aapl_stock.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:45.156567Z",
     "start_time": "2021-06-07T16:34:44.927380Z"
    }
   },
   "outputs": [],
   "source": [
    "pe = aapl_stock.AdjClose.to_frame('price').join(eps.to_frame('eps'))\n",
    "pe = pe.fillna(method='ffill').dropna()\n",
    "pe['P/E Ratio'] = pe.price.div(pe.eps)\n",
    "pe['P/E Ratio'].plot(lw=2, figsize=(14, 6), title='TTM P/E Ratio');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:45.164600Z",
     "start_time": "2021-06-07T16:34:45.158039Z"
    }
   },
   "outputs": [],
   "source": [
    "pe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:45.663224Z",
     "start_time": "2021-06-07T16:34:45.165662Z"
    }
   },
   "outputs": [],
   "source": [
    "axes = pe.plot(subplots=True, figsize=(16,8), legend=False, lw=2)\n",
    "axes[0].set_title('Adj. Close Price')\n",
    "axes[1].set_title('Diluted Earnings per Share')\n",
    "axes[2].set_title('Trailing P/E Ratio')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Additional Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The field `tag` references values defined in the taxonomy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:45.669973Z",
     "start_time": "2021-06-07T16:34:45.664053Z"
    }
   },
   "outputs": [],
   "source": [
    "aapl_nums.tag.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select values of interest and track their value or use them as inputs to compute fundamental metrics like the Dividend/Share ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividends per Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:45.679459Z",
     "start_time": "2021-06-07T16:34:45.670870Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fields = ['EarningsPerShareDiluted',\n",
    "          'PaymentsOfDividendsCommonStock',\n",
    "          'WeightedAverageNumberOfDilutedSharesOutstanding',\n",
    "          'OperatingIncomeLoss',\n",
    "          'NetIncomeLoss',\n",
    "          'GrossProfit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:45.848537Z",
     "start_time": "2021-06-07T16:34:45.680361Z"
    }
   },
   "outputs": [],
   "source": [
    "dividends = (aapl_nums\n",
    "             .loc[aapl_nums.tag == 'PaymentsOfDividendsCommonStock', ['ddate', 'value']]\n",
    "             .groupby('ddate')\n",
    "             .mean())\n",
    "shares = (aapl_nums\n",
    "          .loc[aapl_nums.tag == 'WeightedAverageNumberOfDilutedSharesOutstanding', ['ddate', 'value']]\n",
    "          .drop_duplicates()\n",
    "          .groupby('ddate')\n",
    "          .mean())\n",
    "df = dividends.div(shares).dropna()\n",
    "ax = df.plot.bar(figsize=(14, 5), title='Dividends per Share', legend=False)\n",
    "ax.xaxis.set_major_formatter(mticker.FixedFormatter(df.index.strftime('%Y-%m')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Textual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:47.940909Z",
     "start_time": "2021-06-07T16:34:45.849479Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txt = pd.read_parquet(data_path / '2016_2' / 'parquet' /  'txt.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AAPL's adsh is not avaialble in the txt file but you can obtain notes from the financial statements here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T16:34:47.962984Z",
     "start_time": "2021-06-07T16:34:47.941779Z"
    }
   },
   "outputs": [],
   "source": [
    "txt.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algotd",
   "language": "python",
   "name": "algotd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
